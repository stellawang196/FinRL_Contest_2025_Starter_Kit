
# FinRL Task 2 - AlphaSeek Crypto
This task aims to develop robust and effective trading agents for cryptocurrencies through factor mining and ensemble learning. In this task, participants are expected to explore useful factors and ensemble methods for crypto trading. Participants are free to apply various techniques to the factor engineering process, design component models, and use innovative methods to increase the diversity of component models in the ensemble. They also need to specify the state space, action space and reward function in the environment. The final model should be able to interact with the provided trading environment.

The code in this repo contains a comprehensive starter kit to get started with training single agents in massively parallel environments. 

## Starter Kit Description

This starter kit demonstrates how to use the provided code. We provide you with RNN generated strong factors to use for the DRL agent. You are welcome to experiment with various ensemble configurations that yield optimal results. 

### Supervised Training of Deep Learning Recurrent Networks

- `seq_data.py`: Reads BTC's CSV data and generates Alpha101 weak factors.
  - Function `convert_csv_to_level5_csv`: Reads a CSV file into a DataFrame, then extracts the required level5 data, and saves it back as a CSV.
  - Function `convert_btc_csv_to_btc_npy`: Reads a CSV file, saves it as an array, and linearly transforms it to between ±1 using min-max values, saving as an npy. (z-score)

- `seq_net.py`: Feeds a time series into a recurrent network `(LSTM+GRU + MLP)` to predict another time series as the label.
  - Class `RnnRegNet`: Processes `input_seq → Concatenate(LSTM, GRU) → RegressionMLP → label_seq`

- `seq_run.py`: Inputs Alpha101 weak factor series to train the deep learning recurrent network, predicting future price movement labels.
  - Class `SeqData`: Prepares the input and output sequences for training the neural network, using the function `sample_for_train` to randomly cut sequences for training.
  - Function `train_model`: Uses the condition "number of steps without improvement in loss reaches the set limit" as the criterion for early stopping during training.

- `seq_record.py`: Records the training process logs and plots the loss function graph.
  - Class `Evaluator`: Evaluates model performance during training, tracking accuracy and loss values.
  - Class `Validator`: Visualizes evaluation results during training.

### Reinforcement Learning DQN Algorithm Training in a Market Replay Simulator

- `trade_simulator.py`: Contains a market replay simulator for single commodity.
  - Class `TradeSimulator`: A training-focused market replay simulator, complying with the older gym-style API requirements.
  - Class `EvalTradeSimulator`: A market replay simulator for evaluation.

- `erl_config.py`: Configuration file for reinforcement learning training.

- `erl_replay_buffer.py`: Serves as a training dataset for the reinforcement learning market replay simulator.

- `erl_agent.py`: Contains the DQN class algorithm for reinforcement learning.

- `erl_net.py`: Neural network structures used in the reinforcement learning algorithm.

- `erl_run.py`: Loads the simulator and trains the reinforcement learning agent.

- `erl_evaluator.py`: Evaluates the performance of the reinforcement learning agent.

- `metrics.py`: Contains some metrics for evaluation.

- `task2_ensemble.py`: This file contains code that trains multiple models and then saves them to be tested during evaluation.

- `task2_eval.py`: This file contains code that loads your ensemble and simulates trading over a validation dataset. You may create this validation dataset by holding out a part of the training data.

## Dataset

A dataset containing second-level Limit Order Book (LOB) data for Bitcoin is provided. Please download [here](https://drive.google.com/drive/folders/1Okd8fyB7n93N1Z5HEnlpb-q8x5FfSF1Z?usp=sharing). All of the datasets required to train DRL agents are in the data directory, please download this into the Task_1 starter dir 

The dataset contains the following files: 
- BTC_1sec.csv : 1 second level LOB BTC data
- BTC_1sec_predict.npy : strong RNN factors generated on the csv dataset to train the DRL agent

We generate the strong RNN features by first training a RNN model on 60% of the dataset. The RNN is trained to predict future price movements using 101 formulaic alphas [1]. The strong factors generated by RNN are used as technical factors to train the FinRL agent. The FinRL agent will be trained on the remaining dataset, and then evaluated on a separate test set. The RNN we use combines LSTM and GRU networks for better data modeling. It uses a MLP input layer to process the alpha101 features followed by two RNN networks to model the data.

The `BTC_1sec.csv` contains all data used to train the RNN model and FinRL agent. Notice that the timestamps in this dataset has been processed and are not the true timestamps. 

## Setup



## Evaluation

The initial cash is $1 million.

For evaluatiuon, we will run your ensemble agents on a test set and compare the results using metrics like cumulative return, win loss rate and sharpe ratio (subject to change). 

## Submission

Please submit all your models and the scripts to load and test the models.

Please provide a readme that describes your submission and explains important things to note when running it so that we can ensure we run your submission as it was intended.

```
├── finrl-contest-task-2 
│ ├── trained_models # Your trained component agent weights.
│ ├── task1_ensemble.py # File for implementing the ensemble method 
│ ├── task1_eval.py # a template evaluation file. Please submit your evaluation code as well.
│ ├── trade_simulator.py # File for the environment. Please submit it if you modified the provided env.
│ ├── READE.md # File to explain the your code
│ ├── requirements.txt # Have it if adding any new packages
│ ├── And any additional scripts you create
```